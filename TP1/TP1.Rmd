---
title: "TP1 Regresión Lineal Simple"
author: "Marcos Buccellato"
date: '2023-06-01'
output:
  word_document:
    toc: yes
    toc_depth: '5'
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    toc: yes
    toc_depth: 5
    number_sections: no
    toc_float:
      collapsed: no
      smooth_scroll: yes
editor_options:
  markdown:
    wrap: 72
always_allow_html: yes
---

```{r setup, warning=FALSE, cache=FALSE, message=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(readxl)
library(MVN)
library(gridExtra)
```



# 1.1.Correlación 

## Ejercicio1.1.

En el archivo grasacerdos.xlsx se encuentran los datos del peso  vivo  (PV,en Kg) y al epesor de grasa dorsal(EGD,en mm) de 30 lechones elegidos al azar de una población de porcinos Duroc Jersey del Oeste de la provincia de Buenos Aires. Se pide 


```{r warning=FALSE, cache=FALSE, message=FALSE}

grasa <- read_excel('grasacerdos.xlsx')
grasa$PV <- as.numeric(gsub(",", ".", grasa$PV))
grasa$EGD <- as.numeric(gsub(",", ".", grasa$EGD))
```


### (a)Dibujar el diagrama de dispersión e interpretarlo.

```{r}
ggplot(grasa, aes(PV, EGD)) + 
  geom_point() + theme_minimal()
```
Como cambia el EGD en función del crecimiento del PV.

### (b)Calcular el coeficiente de correlación muestral y explíquelo. 

```{r}
biNormTest <- mvn(data = grasa[2:3], mvnTest = "hz")
corCoeff <- cor(grasa$PV,grasa$EGD, method = "pearson")
print(biNormTest$multivariateNormality)
```
Como el test de binormalidad de las variables dio positivo, puedo usar el coeficiente de perason como indicador de la correlación entre las variables. 

### (c)¿Hay suficiente evidencia para admitir asociación entre el peso y el espesor de grasa? (α=0,05). Verifique los supuestos para decidir el indicador que va a utilizar.

```{r}
corTest <- cor.test(grasa$PV,grasa$EGD, method = "pearson") 

```

El resultado de un test de correlación (usando Pearson según se vio en (b)) dio negativo con un p valor de `r corTest$p.value` que es mayor al $\alpha$ = 0,05

## Ejercicio1.2.
Los datos del cuarteto de Anscombe se encuentran en el archivo anscombe.xlsx

```{r warning=FALSE, cache=FALSE, message=FALSE}
anscombre <- read_excel('anscombe.xlsx')
```

Se pide explorar los datos de la siguiente manera: 

### (a) Graficar los cuatro pares de datos en un diagrama de dispersión cada uno.

```{r}
c1 <- ggplot(anscombe, aes(x1, y1)) + 
  geom_point() + theme_minimal()
c2 <- ggplot(anscombe, aes(x2, y2))+ 
  geom_point() + theme_minimal()
c3 <- ggplot(anscombe, aes(x3, y3))+ 
  geom_point() + theme_minimal()
c4 <- ggplot(anscombe, aes(x4, y4))+ 
  geom_point() + theme_minimal()
grid.arrange(c1,c2,c3,c4, ncol = 2, nrow = 2)
```

### (b) Hallar los valores medios de las variables para cada par de datos.

```{r}
colMeans(anscombe)
```

### (c) Hallar los valores de la dispersión para cada conjunto de datos. 
```{r}
sapply(anscombe, sd)
```
### (d) Hallar el coeficiente muestral de correlación lineal en cada caso.

```{r warning=FALSE}
mvn(data = anscombe[c(1,5)], mvnTest = "hz")$multivariateNormality$MVN
mvn(data = anscombe[c(2,6)], mvnTest = "hz")$multivariateNormality$MVN
mvn(data = anscombe[c(3,7)], mvnTest = "hz")$multivariateNormality$MVN
mvn(data = anscombe[c(4,8)], mvnTest = "hz")$multivariateNormality$MVN
cor.test(anscombe$x1,anscombe$y1,method="pearson")$p.value
cor.test(anscombe$x2,anscombe$y2,method="spearman")$p.value
cor.test(anscombe$x3,anscombe$y3,method="spearman")$p.value
cor.test(anscombe$x4,anscombe$y4,method="spearman")$p.value

```

### (e) Observar, comentar y concluir.

Los primeros pares de variables son binormales por lo tanto puedo usar pearson. Hay correlación porque ep p-valor es bajo. EN los siguientes no podría usar pearson porque no son binormales, por tal motivo uso spearman. Hay correlación salvo en el caso del cuarto par de variables.


# 1.2.Modelo Lineal Simple

## Ejercicio1.3.
El archivo peso_edad_colest.xlsx disponible en contiene registros correspondiente sa 25 individuos respecto de supeso, su edad y el nivel de colesterol total en sangre.

```{r warning=FALSE, cache=FALSE, message=FALSE}
colest <- read_excel('peso_edad_colest.xlsx')
```

Se pide:

### (a) Realizar el diagrama de dispersión de colesterol en función de la edad y de colesterol en función de peso. Le parece adecuado ajustar un modelo lineal para alguno de estos dos pares de variables? 

```{r}
promedios <- colMeans(colest)

c1 <- ggplot(colest, aes(edad, colest)) + 
  geom_point() +
  geom_vline(xintercept=promedios[2],linetype="dotted") + 
  geom_hline(yintercept=promedios[3],linetype="dotted") + 
  theme_minimal()
c2 <- ggplot(colest, aes(peso, colest)) + 
  geom_point() + 
  geom_vline(xintercept=promedios[1],linetype="dotted") +
  geom_hline(yintercept=promedios[3],linetype="dotted") + 
  theme_minimal()
grid.arrange(c1,c2, ncol = 1, nrow = 2)

```

En aparencia colest ~ peso parecería poder ajustarse linealmente.

### (b) Estime los coeficientes del modelo lineal para el colesterol en función de la edad. 

```{r}

model <- lm(colest ~ edad, data = colest)
model$coefficients

```
```{r warning=FALSE,message=FALSE}
(c1+ geom_smooth(method = "lm", se = TRUE, color = "black") )

```


### (c) Estime intervalos de confianza del 95% para los coeficientes del modelo y compare estos resultados con el test de Wald para los coeficientes.Le parece que hay asociación entre estos test y el test de la regresión? 

cálculo de coeficientes de confianza:
```{r}
ci <- confint(model, level = 0.95)
ci
```
test de Wald:

```{r}
#install.packages("aod")
library(aod)
coef(model)
wald.test(Sigma = vcov(model), b = coef(model), Terms = 1)

```
<span style="color: red;">No se muy bien que concluir. Pero entiendo que el test de wald en este caso probaría que existe un coeficiente que es diferente de cero de forma significativa. En este caso el intervalo del coeficiente no incluye al cero, por lo cual sería consistente.</span>

### (d) A partir de esta recta estime los valores de E(Y) para x=25 años y  x=48 años. Podría estimarse el valor de E(Y) para x=80 años?


```{r}
predict(model, newdata = data.frame(edad = c(25,80)))
```

### (e) Testee la normalidad de los residuos y haga un gráfico para ver si son homocedásticos.

```{r}

shapiro.test(model$residuals)
```
```{r warning=FALSE}
colest2<-colest
colest2$prediccion <- model$fitted.values 
colest2$residuos <- model$residuals


ggplot(data = colest2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")


ggplot(data = colest2, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(model$residuals) 
qqline(model$residuals)


```


Están normalmente distribuidos porque el test falló en rechazar la hipótesis nula de que no están normalmente distribuidos. En el qqplot se pueden ver los valores alineados a la diagonal, lo cual indica coincidencia cercana con los cuantiles teóricos.

```{r,echo=TRUE, warning=FALSE}
#install.packages("lmtest")
library(lmtest) 
bptest(model)
```
Concluimos que se rechaza heteroscedasticidad porque el p-valor para rechazar homocedasticidad no es menor a 0.05 siendo los residuos normales y la relación lineal.

Habría que ver la independencia de las variables para ver si el resultado se mantiene, aplicamos el test de  Durbin-Watson:

```{r,echo=TRUE, warning=FALSE, message=FALSE}
library(car)
dwt(model)
```
La hipótesis nula de este test es la no autocorrelación, en este caso no se puede descartar la misma. Esto implica que no se sostiene el supuesto de independencia. Por tal motivo la conclusión del test anterior no se puede aplicar.

Graficamos:

```{r}

ggplot(colest2, aes(x = prediccion, y = residuos)) +
  geom_point(shape = 20) +
  labs(x = "Predicción", y = "Residuos",
       title = "Residuos vs. Predicción")
```

No parece haber un patrón entre los residuos, por lo cual no se puede ver heterocedasticidad. En clase el código para ver esto era este:

```{r,echo=TRUE}
ggplot(data = colest2, aes(x = seq_along(residuos), y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_line(size = 0.3) + labs(title = "Distribución de los residuos", x = "index", y = "residuo")+ 
  geom_hline(yintercept = 0) + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")

```

<span style="color: red;">No me queda claro como interpretarlo en este caso</span>

## Ejercicio1.4. Una empresa desarrolló un sistema de energía solar para calentar el agua para una caldera que es parte del sistema de energía del proceso productivo.Existe el interés de controlar la estabilidad del sistema, para ello se monitorea el mismo y se registran los datos cada hora. Los datos se encuentran disponibles en el archivo energia.xlsx
```{r warning=FALSE, cache=FALSE, message=FALSE}
energia <- read_excel('energia.xlsx')
```

### (a) Realizar el diagrama de dispersión y evaluar si un modelo de regresión lineal es adecuado. 

```{r}
promediosE <- colMeans(energia)
ggplot(energia, aes(Hora, Energía)) + 
  geom_point() +
  geom_vline(xintercept=promediosE[1],linetype="dotted") + 
  geom_hline(yintercept=promediosE[2],linetype="dotted") + 
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```

No parecería ser adecuado un modelo lineal




### (b) Estimar un modelo lineal y verificar la normalidad de los residuos del mismo.


```{r}

modelE <- lm(Energía ~ Hora, data = energia)

shapiro.test(modelE$residuals)

```

No están normalmente distribuidos porque el test rechaza la hipótesis nula de que no están normalmente distribuidos.

```{r}

summary(modelE)
```

Más aun porque el R ajustado es bajisimo, el p-value de los coefficientes tambien y el p-value del F-test también.....


```{r warning=FALSE}
energia2<-energia
energia2$prediccion <- modelE$fitted.values 
energia2$residuos <- modelE$residuals


ggplot(data = energia2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")


ggplot(data = energia2, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(modelE$residuals) 
qqline(modelE$residuals)


```
Graficamos:

```{r}

ggplot(energia2, aes(x = prediccion, y = residuos)) +
  geom_point(shape = 20) +
  labs(x = "Predicción", y = "Residuos",
       title = "Residuos vs. Predicción")
```
Aparentemente en este caso no hay normalidad porque hay agrupamiento de los residuos habiendo algunos puntos que se alejan mucho del resto

### (c) En caso de rechazar este supuesto buscar una transformación lineal para este modelo y aplicarla. 

```{r}
library(MASS)

box_cox_result <-boxcox(Energía ~ Hora, lambda = -5:2, data = energia)
best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]
modelE2 <- lm((Energía)^(best_box_cox) ~ Hora, data = energia)
summary(modelE2)
shapiro.test(modelE2$residuals)
```


```{r}
energia3<-energia
energia3$Energía <- log(energia$Energía)
energia3$prediccion <- modelE2$fitted.values 
energia3$residuos <- modelE2$residuals


ggplot(data = energia3, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(modelE2$residuals) 
qqline(modelE2$residuals)
```






### (d) Realizar el análisis diagnóstico del nuevo modelo y estimar un intervalo de confianza y un intervalo de predicción para 27.5 hs con ambos modelos. Comparar los intervalos.

```{r}

shapiro.test(modelE2$residuals)
```
Con el test de shapiro-wilk ahora no se descarta normalidad.



Los intervalos de confianza son:

```{r}
ci <- confint(modelE2, level = 0.95)
ci

```
Predicción:
```{r}
predict(modelE2, newdata = data.frame(Hora = c(27.5)))
```
```{r message=FALSE}
promediosE2 <- colMeans(energia3)
ggplot(energia3, aes(Hora, Energía)) + 
  geom_point() +
  geom_vline(xintercept=promediosE2[1],linetype="dotted") + 
  geom_hline(yintercept=promediosE2[2],linetype="dotted") + 
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```


<span style="color: red;">No termino de entender el sentido de este ejercicio, a las claras se ve que no hay un fit muy adecuado con una recta ¿para que tanta manipulación? Es como querer encajarlo a martillazos </span>

# 1.4.Tratamiento de la heterocedasticidad

## Ejercicio1.5. Se obtuvieron datos históricos del mercado inmobiliario de una  ciudad de Nueva Taipei,en Taiwan.La base es inmobiliaria.xlsx. 

Las características son:  

edad: Edad de la propiedad (en años). 
distancia: La distancia a la estación de transporte más cercana (en metros).
negocios: Cantidad de negocios de conveniencia en las cercanías a una distancia realizable a pie.
latitud: Latitud de la ubicación de la propiedad (en grados).
longitud: Longitud de la ubicación de la propiedad (en grados). 
precio: Precio por metro cuadrado (en miles de dólares) 


```{r warning=FALSE, cache=FALSE, message=FALSE}
propiedades <- read_delim('inmobiliaria.csv',col_names = TRUE,delim=";")
```

Se quiere investigar si el precio de las propiedades puede ser estimado en función de alguna de las variables disponibles. 

### (a) Analizar si el precio depende de alguna de las variables. 
<span style="color: red;">No me queda claro el sentido de trabajar con latitud y longitud, sobre todo por separado. Quizas estaría bueno hacer una regresion multivariada en ese caso. En tal caso haría algo así: http://www.geo.hunter.cuny.edu/~ssun/R-Spatial/spregression.html</span>

```{r message=FALSE}
promediosP <- colMeans(propiedades)
c1 <- ggplot(propiedades, aes(edad, precio)) + 
  geom_point() +
  geom_vline(xintercept=promediosP[1],linetype="dotted") + 
  geom_hline(yintercept=promediosP[6],linetype="dotted") +
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
c2 <- ggplot(propiedades, aes(distancia, precio)) + 
  geom_point() + 
  geom_vline(xintercept=promediosP[2],linetype="dotted") +
  geom_hline(yintercept=promediosP[6],linetype="dotted") + 
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
c3 <- ggplot(propiedades, aes(negocios, precio)) + 
  geom_point() +
  geom_vline(xintercept=promediosP[3],linetype="dotted") + 
  geom_hline(yintercept=promediosP[6],linetype="dotted") + 
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()

grid.arrange(c1,c2,c3, ncol = 3, nrow = 1)
```

```{r}

biNormTest <- mvn(data = propiedades[c(6,1)], mvnTest = "hz")
print(biNormTest$multivariateNormality$MVN)
biNormTest <- mvn(data = propiedades[c(6,2)], mvnTest = "hz")
print(biNormTest$multivariateNormality$MVN)
biNormTest <- mvn(data = propiedades[c(6,3)], mvnTest = "hz")
print(biNormTest$multivariateNormality$MVN)
```

En ninguno de los tres casos da positivo el test de binormalidad, por lo tanto para ver la correlación voy a usar spearman

```{r warning=FALSE}
cor.test(propiedades$precio,propiedades$edad,method="spearman")$p.value
cor.test(propiedades$precio,propiedades$distancia,method="spearman")$p.value
cor.test(propiedades$precio,propiedades$negocios,method="spearman")$p.value
```
En este caso estarían todas correlacionadas

```{r}
library(corrplot)
corrplot(cor(propiedades,method="s"))
```


### (b) Estudiar la linealidad de la relación precio-distancia.

```{r}

modelProp <- lm(precio ~ distancia, data = propiedades)

shapiro.test(modelProp$residuals)
```
No estan normalmente distribuidos los residuos porque el test valida la hipotesis alternativa de que no lo estan.


### (c) Estimar los coeficientes del modelo y realizar el análisis diagnóstico de los residuos del mismo. Utilizar para este análisis los gráficos de residuos versus valores ajustados, el qq-plot de los residuos, la grafica de residuos versus leverage. 


```{r}
prop2<-propiedades
prop2$prediccion <- modelProp$fitted.values 
prop2$residuos <- modelProp$residuals

d1 <- ggplot(data = prop2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")


d2<- ggplot(data = prop2, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(modelProp$residuals) 
qqline(modelProp$residuals)
grid.arrange(d1,d2,nrow = 2)
```

De todas maneras, esto parece ser más producto de outliers que otra cosa.


Otra forma de verlo:
```{r}
par(mfrow=c(2,2))
plot(modelProp)
par(mfrow=c(1,1))
```
El dato 266 al menos parece ser outlier



### (d) Aplicar los test de Durbin-Watson Breush-Pagan.
```{r}
#Durbin-Watson
library(lmtest)
dwtest(modelProp,alternative ="two.sided",iterations=1000)


```
No rechaza la hipótesis de NO autocorrelación y no tienen distribución normal.... no serían independientes pero <span style="color:darkred">No me queda claro como sería el tema cuando no es normal la distribución como interpretar el test de independencia.</span>


### (e) Analice la presencia de outlier y verifique si coinciden con los puntos influyentes.


```{r}

summary(influence.measures(model = modelProp))

```
# 1.5. Cuadrados Mínimos Ponderados

## Ejercicio1.6. En la base estudio.xlsx se encuentran registradas las horas de  estudios referidas por un conjunto de estudiantes y su calificación en la evaluación final.

```{r}

estudio16 <- read_delim('estudio.csv',col_names = TRUE,delim=";",show_col_types = FALSE)
```


### (a) Ajuste un modelo de regresión simple para estimar la nota final en función de las horas dedicadas al estudio.

```{r}

model16 <- lm(puntaje ~ horas_estudio, data = estudio16)
promedios16 <- colMeans(estudio16)
ggplot(estudio16, aes(horas_estudio, puntaje)) + 
  geom_point() +
  geom_vline(xintercept=promedios16[1],linetype="dotted") + 
  geom_hline(yintercept=promedios16[2],linetype="dotted") +
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()

```

### (b) Estudie el cumplimiento de los supuestos del modelo, gráfica y analíticamente.

**Análisis gráfico**

De la gráfica que se puede ver en el punto **a)** encontramos que hay algunos puntos que parecen ser outliers e influyentes. Vemos que en apariencia la estimación lineal puede ser apropiada pero es probable que estos puntos influyentes afecten la estimación.

**Indicadores**

Testeamos la binormalidad primero para ver que método usamos para estimar correlación.
```{r}
biNormTest16 <- mvn(data = estudio16, mvnTest = "hz")
print(biNormTest16$multivariateNormality)
```
Como este test da negativo, entonces debo usar el método de Spearman para ver la correlación.

```{r}

corTest16 <- cor.test(estudio16$horas_estudio, estudio16$puntaje, method = "spearman") 
corTest16
```
Da una correlación positiva con un p-valor muy bajo, verificando lo sospechado en el análisis gráfico.
```{r}
summary(model16)
```
 Si vemos los resultados del modelo lineal podemos verificar lo mismo. Tenemos bajos p-valores en la prueba de wald de los coeficientes y un p-valor bajo el test F. Vemos tambien que tanto R como R-ajustado nos indican que esta relación explica el 50% de los datos y esto coincide con el análisis previo. 
 
**Normalidad de los residuos**

Estudiemos si hacer una regresión lineal es la mejor opción:

```{r}

shapiro.test(model16$residuals)
```
La hipotesis nula de este test es que los residuos están normalmente distribuidos y la alternativa es que no lo están, como el test rechaza la hipótesis nula, concluimos que no están normalmente distribuidos. Veamoslo en un qqplot

```{r}
qqnorm(model16$residuals) 
qqline(model16$residuals)
```
Vemos algunos puntos en los extremos que se alejan. Pero parte de las discrepancias podrían deberse a outliers.

```{r}

model16b <- data.frame(prediccion = model16$fitted.values,
                       residuos = model16$residuals)


d1_16 <- ggplot(data = model16b, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")


d2_16<- ggplot(data = model16b, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(d1_16,d2_16,nrow = 2)
```
Vemos una cierta fórma cónica en los residuos y que la distribución no parece muy normal.

Veamos ahora si los residuos estan aoutocorrelacionados, es decir si hay algún tipo de relación entre lo que paso en una medida y las siguientes. A priori conceptualmente no debería haberlas, pero por ahí detectamos autocorrelación y eso nos podría cuestionar la forma en la que se tomaron las mediciones por ejemplo.

```{r}
#Durbin-Watson
dwtest(model16,alternative ="two.sided",iterations=1000)
```
La hipótesis nula es que NO hay autocorrelación.  

Analizemos la heterocedasticidad de los residuos.

```{r}
bptest(model16)
```
Los residuos son heterocedasticos porque se rechaza la hipotesis nula de homocedasticidad. Es decir que la varianza no es constante para los diversos valores estimados.

**Resumen:**

 * Normalidad: NO
 * Independencia: Sí (que no sean normales no afecta?)
 * Homcedasticidad: NO


**Outliers**

 Hagamos un análisis gráfico de otra forma menos vistosos pero más rápido: 
```{r}
par(mfrow=c(2,2))
plot(model16)
par(mfrow=c(1,1))

```
Ya habíamos adelantado que podía haber outliers que sean puntos influyentes. De este análisis gráfico rápido, surgen algunos posibles candidatos.


```{r}
summary(influence.measures(model = model16))
```
El punto 36 parece ser el más obvio candidato

```{r}
outlierTest(model16)
```
```{r}
influencePlot(model = model16)
influenceIndexPlot(model16, vars='Bonf', las=1,col='green')

```
Podemos concluir que el punto 36 es un outlier

### (c) Ajuste un modelo de mínimos cuadrados ponderados definiendo los pesos de tal manera que las observaciones con menor varianza tengan más peso.

Creamos un vector de ponderaciones que devuelve los valores que salen de la regresión lineal entre los residuos en valor absoluto del modelo original y sus valores estimados y al reciproco lo elevamos al cuadrado. Es decir que construimos un estimador de el residuo dado su valor estimado, lo elevamos al cuadrado para potenciar la diferencia y luego aplicamos la reciproca para que esa diferencia penalice más.

```{r, echo=TRUE}
ww<-1 / lm(abs(model16$residuals) ~ model16$fitted.values)$fitted.values^2

plot(estudio16$horas_estudio,estudio16$puntaje,xlab="Horas de estudio",ylab="Puntaje",
     main="Horas vs Puntaje")

abline(model16,col="darkviolet",lwd=2)

model16_ww<- lm(puntaje ~ horas_estudio, data = estudio16,weights =ww)
abline(model16_ww,col="hotpink",lwd=2)
```
Comparando graficamente vemos que ambas regresiones son diferentes y la ajustada no se ve tan influenciada por el valor 36, por tal motivo tiene una pendiente mayor. Pero este ajuste también suaviza los efectos de cualquier otro residuo alejado
### (d) Realice el análisis diagnóstico del segundo modelo ajustado.
Hagamos el diagnóstico anterior:


**Modelo lineal**
```{r}
summary(model16_ww)
```
Los p-valores del  test de wald, los coeficientes dan ok. Pero ahora el R y R ajustado explican el 76% de los datos, lo cual mejora mucho el modelo.

**Normalidad de los residuos**

```{r}

shapiro.test(model16_ww$residuals)
```
La hipotesis nula de este test es que los residuos están normalmente distribuidos y la alternativa es que no lo están, como el test rechaza la hipótesis nula, concluimos que no están normalmente distribuidos al igual que el modelo anterior.


**Independencia de los residuos**


```{r}
dwtest(model16_ww)
```


<span style="color: red;">Como se hace esto para modelos ponderados</span>

**Homocedasticidad**

```{r}
bptest(model16_ww)
```
Los residuos son homocedasticos porque no se rechaza en este caso la hipotesis nula de homocedasticidad.

**Resumen**

* Normalidad de residuos: NO
* Independencia: SÍ
* Homocedasticidad: SÍ

### (e) Compare ambos ajustes realizados y concluya.

Se compararon los modelos y en los puntos anteriores.