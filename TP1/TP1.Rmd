---
title: "TP1 Regresión Lineal Simple"
author: "Marcos Buccellato"
date: '2023-06-01'
output:
  html_document:
    toc: yes
    toc_depth: 5
    number_sections: no
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: yes
    toc_depth: '5'
  word_document:
    toc: yes
    toc_depth: '5'
editor_options:
  markdown:
    wrap: 72
always_allow_html: yes
---

```{r setup, warning=FALSE, cache=FALSE, message=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(readxl)
library(MVN)
library(gridExtra)
```



# 1.1.Correlación 

## Ejercicio1.1.

En el archivo grasacerdos.xlsx se encuentran los datos del peso  vivo  (PV,en Kg) y al epesor de grasa dorsal(EGD,en mm) de 30 lechones elegidos al azar de una población de porcinos Duroc Jersey del Oeste de la provincia de Buenos Aires. Se pide 


```{r warning=FALSE, cache=FALSE, message=FALSE}

grasa <- read_excel('grasacerdos.xlsx')
grasa$PV <- as.numeric(gsub(",", ".", grasa$PV))
grasa$EGD <- as.numeric(gsub(",", ".", grasa$EGD))
```


### (a)Dibujar el diagrama de dispersión e interpretarlo.

```{r}
ggplot(grasa, aes(PV, EGD)) + 
  geom_point() + theme_minimal()
```
Como cambia el EGD en función del crecimiento del PV.

### (b)Calcular el coeficiente de correlación muestral y explíquelo. 

```{r}
biNormTest <- mvn(data = grasa[2:3], mvnTest = "hz")
corCoeff <- cor(grasa$PV,grasa$EGD, method = "pearson")
print(biNormTest$multivariateNormality)
```
Como el test de binormalidad de las variables dio positivo, puedo usar el coeficiente de perason como indicador de la correlación entre las variables. 

### (c)¿Hay suficiente evidencia para admitir asociación entre el peso y el espesor de grasa? (α=0,05). Verifique los supuestos para decidir el indicador que va a utilizar.

```{r}
corTest <- cor.test(grasa$PV,grasa$EGD, method = "pearson") 

```

El resultado de un test de correlación (usando Pearson según se vio en (b)) dio negativo con un p valor de `r corTest$p.value` que es mayor al $\alpha$ = 0,05

## Ejercicio1.2.
Los datos del cuarteto de Anscombe se encuentran en el archivo anscombe.xlsx

```{r warning=FALSE, cache=FALSE, message=FALSE}
anscombre <- read_excel('anscombe.xlsx')
```

Se pide explorar los datos de la siguiente manera: 

### (a) Graficar los cuatro pares de datos en un diagrama de dispersión cada uno.

```{r}
c1 <- ggplot(anscombe, aes(x1, y1)) + 
  geom_point() + theme_minimal()
c2 <- ggplot(anscombe, aes(x2, y2))+ 
  geom_point() + theme_minimal()
c3 <- ggplot(anscombe, aes(x3, y3))+ 
  geom_point() + theme_minimal()
c4 <- ggplot(anscombe, aes(x4, y4))+ 
  geom_point() + theme_minimal()
grid.arrange(c1,c2,c3,c4, ncol = 2, nrow = 2)
```

### (b) Hallar los valores medios de las variables para cada par de datos.

```{r}
colMeans(anscombe)
```

### (c) Hallar los valores de la dispersión para cada conjunto de datos. 
```{r}
sapply(anscombe, sd)
```
### (d) Hallar el coeficiente muestral de correlación lineal en cada caso.

```{r warning=FALSE}
mvn(data = anscombe[c(1,5)], mvnTest = "hz")$multivariateNormality$MVN
mvn(data = anscombe[c(2,6)], mvnTest = "hz")$multivariateNormality$MVN
mvn(data = anscombe[c(3,7)], mvnTest = "hz")$multivariateNormality$MVN
mvn(data = anscombe[c(4,8)], mvnTest = "hz")$multivariateNormality$MVN
cor.test(anscombe$x1,anscombe$y1,method="pearson")$p.value
cor.test(anscombe$x2,anscombe$y2,method="spearman")$p.value
cor.test(anscombe$x3,anscombe$y3,method="spearman")$p.value
cor.test(anscombe$x4,anscombe$y4,method="spearman")$p.value

```

### (e) Observar, comentar y concluir.

Los primeros pares de variables son binormales por lo tanto puedo usar pearson. Hay correlación porque ep p-valor es bajo. EN los siguientes no podría usar pearson porque no son binormales, por tal motivo uso spearman. Hay correlación salvo en el caso del cuarto par de variables.


# 1.2.Modelo Lineal Simple

## Ejercicio1.3.
El archivo peso_edad_colest.xlsx disponible en contiene registros correspondiente sa 25 individuos respecto de supeso, su edad y el nivel de colesterol total en sangre.

```{r warning=FALSE, cache=FALSE, message=FALSE}
colest <- read_excel('peso_edad_colest.xlsx')
```

Se pide:

### (a) Realizar el diagrama de dispersión de colesterol en función de la edad y de colesterol en función de peso. Le parece adecuado ajustar un modelo lineal para alguno de estos dos pares de variables? 

```{r}
promedios <- colMeans(colest)

c1 <- ggplot(colest, aes(edad, colest)) + 
  geom_point() +
  geom_vline(xintercept=promedios[2],linetype="dotted") + 
  geom_hline(yintercept=promedios[3],linetype="dotted") + 
  theme_minimal()
c2 <- ggplot(colest, aes(peso, colest)) + 
  geom_point() + 
  geom_vline(xintercept=promedios[1],linetype="dotted") +
  geom_hline(yintercept=promedios[3],linetype="dotted") + 
  theme_minimal()
grid.arrange(c1,c2, ncol = 1, nrow = 2)

```

En aparencia colest ~ peso parecería poder ajustarse linealmente.

### (b) Estime los coeficientes del modelo lineal para el colesterol en función de la edad. 

```{r}

model <- lm(colest ~ edad, data = colest)
model$coefficients

```
```{r warning=FALSE,message=FALSE}
(c1+ geom_smooth(method = "lm", se = TRUE, color = "black") )

```


### (c) Estime intervalos de confianza del 95% para los coeficientes del modelo y compare estos resultados con el test de Wald para los coeficientes.Le parece que hay asociación entre estos test y el test de la regresión? 

cálculo de coeficientes de confianza:
```{r}
ci <- confint(model, level = 0.95)
ci
```
test de Wald:

```{r}
#install.packages("aod")
library(aod)
coef(model)
wald.test(Sigma = vcov(model), b = coef(model), Terms = 1)

```
<span style="color: red;">No se muy bien que concluir. Pero entiendo que el test de wald en este caso probaría que existe un coeficiente que es diferente de cero de forma significativa. En este caso el intervalo del coeficiente no incluye al cero, por lo cual sería consistente.</span>

### (d) A partir de esta recta estime los valores de E(Y) para x=25 años y  x=48 años. Podría estimarse el valor de E(Y) para x=80 años?


```{r}
predict(model, newdata = data.frame(edad = c(25,80)))
```

### (e) Testee la normalidad de los residuos y haga un gráfico para ver si son homocedásticos.

```{r}

shapiro.test(model$residuals)
```
```{r warning=FALSE}
colest2<-colest
colest2$prediccion <- model$fitted.values 
colest2$residuos <- model$residuals


ggplot(data = colest2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")


ggplot(data = colest2, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(model$residuals) 
qqline(model$residuals)


```


Están normalmente distribuidos porque el test falló en rechazar la hipótesis nula de que no están normalmente distribuidos. En el qqplot se pueden ver los valores alineados a la diagonal, lo cual indica coincidencia cercana con los cuantiles teóricos.

```{r,echo=TRUE, warning=FALSE}
#install.packages("lmtest")
library(lmtest) 
bptest(model)
```
Concluimos que se rechaza heteroscedasticidad porque el p-valor para rechazar homocedasticidad no es menor a 0.05 siendo los residuos normales y la relación lineal.

Habría que ver la independencia de las variables para ver si el resultado se mantiene, aplicamos el test de  Durbin-Watson:

```{r,echo=TRUE, warning=FALSE, message=FALSE}
library(car)
dwt(model)
```
La hipótesis nula de este test es la no autocorrelación, en este caso no se puede descartar la misma. Esto implica que no se sostiene el supuesto de independencia. Por tal motivo la conclusión del test anterior no se puede aplicar.

Graficamos:

```{r}

ggplot(colest2, aes(x = prediccion, y = residuos)) +
  geom_point(shape = 20) +
  labs(x = "Predicción", y = "Residuos",
       title = "Residuos vs. Predicción")
```

No parece haber un patrón entre los residuos, por lo cual no se puede ver heterocedasticidad. En clase el código para ver esto era este:

```{r,echo=TRUE}
ggplot(data = colest2, aes(x = seq_along(residuos), y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_line(size = 0.3) + labs(title = "Distribución de los residuos", x = "index", y = "residuo")+ 
  geom_hline(yintercept = 0) + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")

```

<span style="color: red;">No me queda claro como interpretarlo en este caso</span>

## Ejercicio1.4. Una empresa desarrolló un sistema de energía solar para calentar el agua para una caldera que es parte del sistema de energía del proceso productivo.Existe el interés de controlar la estabilidad del sistema, para ello se monitorea el mismo y se registran los datos cada hora. Los datos se encuentran disponibles en el archivo energia.xlsx
```{r warning=FALSE, cache=FALSE, message=FALSE}
energia <- read_excel('energia.xlsx')
```

### (a) Realizar el diagrama de dispersión y evaluar si un modelo de regresión lineal es adecuado. 

```{r}
promediosE <- colMeans(energia)
ggplot(energia, aes(Hora, Energía)) + 
  geom_point() +
  geom_vline(xintercept=promediosE[1],linetype="dotted") + 
  geom_hline(yintercept=promediosE[2],linetype="dotted") + 
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```

No parecería ser adecuado un modelo lineal




### (b) Estimar un modelo lineal y verificar la normalidad de los residuos del mismo.


```{r}

modelE <- lm(Energía ~ Hora, data = energia)

shapiro.test(modelE$residuals)

```

No están normalmente distribuidos porque el test rechaza la hipótesis nula de que no están normalmente distribuidos.

```{r}

summary(modelE)
```

Más aun porque el R ajustado es bajisimo, el p-value de los coefficientes tambien y el p-value del F-test también.....


```{r warning=FALSE}
energia2<-energia
energia2$prediccion <- modelE$fitted.values 
energia2$residuos <- modelE$residuals


ggplot(data = energia2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")


ggplot(data = energia2, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(modelE$residuals) 
qqline(modelE$residuals)


```
Graficamos:

```{r}

ggplot(energia2, aes(x = prediccion, y = residuos)) +
  geom_point(shape = 20) +
  labs(x = "Predicción", y = "Residuos",
       title = "Residuos vs. Predicción")
```
Aparentemente en este caso no hay normalidad porque hay agrupamiento de los residuos habiendo algunos puntos que se alejan mucho del resto

### (c) En caso de rechazar este supuesto buscar una transformación lineal para este modelo y aplicarla. 

```{r}
library(MASS)

box_cox_result <-boxcox(Energía ~ Hora, lambda = -5:2, data = energia)
best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]
modelE2 <- lm((Energía)^(best_box_cox) ~ Hora, data = energia)
summary(modelE2)
shapiro.test(modelE2$residuals)
```


```{r}
energia3<-energia
energia3$Energía <- log(energia$Energía)
energia3$prediccion <- modelE2$fitted.values 
energia3$residuos <- modelE2$residuals


ggplot(data = energia3, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(modelE2$residuals) 
qqline(modelE2$residuals)
```






### (d) Realizar el análisis diagnóstico del nuevo modelo y estimar un intervalo de confianza y un intervalo de predicción para 27.5 hs con ambos modelos. Comparar los intervalos.

```{r}

shapiro.test(modelE2$residuals)
```
Con el test de shapiro-wilk ahora no se descarta normalidad.



Los intervalos de confianza son:

```{r}
ci <- confint(modelE2, level = 0.95)
ci

```
Predicción:
```{r}
predict(modelE2, newdata = data.frame(Hora = c(27.5)))
```
```{r message=FALSE}
promediosE2 <- colMeans(energia3)
ggplot(energia3, aes(Hora, Energía)) + 
  geom_point() +
  geom_vline(xintercept=promediosE2[1],linetype="dotted") + 
  geom_hline(yintercept=promediosE2[2],linetype="dotted") + 
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```


<span style="color: red;">No termino de entender el sentido de este ejercicio, a las claras se ve que no hay un fit muy adecuado con una recta ¿para que tanta manipulación? Es como querer encajarlo a martillazos </span>

# 1.4.Tratamiento de la heterocedasticidad

## Ejercicio1.5. Se obtuvieron datos históricos del mercado inmobiliario de una  ciudad de Nueva Taipei,en Taiwan.La base es inmobiliaria.xlsx. 

Las características son:  

edad: Edad de la propiedad (en años). 
distancia: La distancia a la estación de transporte más cercana (en metros).
negocios: Cantidad de negocios de conveniencia en las cercanías a una distancia realizable a pie.
latitud: Latitud de la ubicación de la propiedad (en grados).
longitud: Longitud de la ubicación de la propiedad (en grados). 
precio: Precio por metro cuadrado (en miles de dólares) 


```{r warning=FALSE, cache=FALSE, message=FALSE}
propiedades <- read_delim('inmobiliaria.csv',col_names = TRUE,delim=";")
```

Se quiere investigar si el precio de las propiedades puede ser estimado en función de alguna de las variables disponibles. 

### (a) Analizar si el precio depende de alguna de las variables. 
<span style="color: red;">No me queda claro el sentido de trabajar con latitud y longitud, sobre todo por separado. Quizas estaría bueno hacer una regresion multivariada en ese caso. En tal caso haría algo así: http://www.geo.hunter.cuny.edu/~ssun/R-Spatial/spregression.html</span>

```{r message=FALSE}
promediosP <- colMeans(propiedades)
c1 <- ggplot(propiedades, aes(edad, precio)) + 
  geom_point() +
  geom_vline(xintercept=promediosP[1],linetype="dotted") + 
  geom_hline(yintercept=promediosP[6],linetype="dotted") +
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
c2 <- ggplot(propiedades, aes(distancia, precio)) + 
  geom_point() + 
  geom_vline(xintercept=promediosP[2],linetype="dotted") +
  geom_hline(yintercept=promediosP[6],linetype="dotted") + 
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
c3 <- ggplot(propiedades, aes(negocios, precio)) + 
  geom_point() +
  geom_vline(xintercept=promediosP[3],linetype="dotted") + 
  geom_hline(yintercept=promediosP[6],linetype="dotted") + 
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()

grid.arrange(c1,c2,c3, ncol = 3, nrow = 1)
```

```{r}

biNormTest <- mvn(data = propiedades[c(6,1)], mvnTest = "hz")
print(biNormTest$multivariateNormality$MVN)
biNormTest <- mvn(data = propiedades[c(6,2)], mvnTest = "hz")
print(biNormTest$multivariateNormality$MVN)
biNormTest <- mvn(data = propiedades[c(6,3)], mvnTest = "hz")
print(biNormTest$multivariateNormality$MVN)
```

En ninguno de los tres casos da positivo el test de binormalidad, por lo tanto para ver la correlación voy a usar spearman

```{r warning=FALSE}
cor.test(propiedades$precio,propiedades$edad,method="spearman")$p.value
cor.test(propiedades$precio,propiedades$distancia,method="spearman")$p.value
cor.test(propiedades$precio,propiedades$negocios,method="spearman")$p.value
```
En este caso estarían todas correlacionadas



### (b) Estudiar la linealidad de la relación precio-distancia.

```{r}

modelProp <- lm(precio ~ distancia, data = propiedades)

shapiro.test(modelProp$residuals)
```
No estan normalmente distribuidos los residuos porque el test valida la hipotesis alternativa de que no lo estan.


### (c) Estimar los coeficientes del modelo y realizar el análisis diagnóstico de los residuos del mismo. Utilizar para este análisis los gráficos de residuos versus valores ajustados, el qq-plot de los residuos, la grafica de residuos versus leverage. 


```{r}
prop2<-propiedades
prop2$prediccion <- modelProp$fitted.values 
prop2$residuos <- modelProp$residuals


ggplot(data = prop2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")


ggplot(data = prop2, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
qqnorm(modelProp$residuals) 
qqline(modelProp$residuals)
```

De todas maneras, esto parece ser más producto de outliers que otra cosa.


Otra forma de verlo:
```{r}
par(mfrow=c(2,2))
plot(modelProp)
par(mfrow=c(1,1))
```
El dato 266 al menos parece ser outlier

```{r}

summary(influence.measures(model = modelProp))

```


### (d) Aplicar los test de Durbin-Watson Breush-Pagan.
### (e) Analice la presencia de outlier y verifique si coinciden con los puntos influyentes.

# 1.5. Cuadrados Mínimos Ponderados

## Ejercicio1.6. En la base estudio.xlsx se encuentran registradas las horas de  estudios referidas por un conjunto de estudiantes y su calificación en la evaluación final.

### (a) Ajuste un modelo de regresión simple para estimar la nota final en función de las horas dedicadas al estudio.
### (b) Estudie el cumplimiento de los supuestos del modelo, gráfica y analíticamente.
### (c) Ajuste un modelo de mínimos cuadrados ponderados definiendo los pesos de tal manera que las observaciones con menor varianza tengan más peso.
### (d) Realice el análisis diagnóstico del segundo modelo ajustado.
### (e) Compare ambos ajustes realizados y concluya.