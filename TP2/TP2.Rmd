---
title: "TP2 ModeloLinealMultivariado"
author: "Marcos Buccellato"
date: '2023-06-30'
output:
  word_document:
    toc: yes
    toc_depth: '5'
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    toc: yes
    toc_depth: 5
    number_sections: no
    toc_float:
      collapsed: no
      smooth_scroll: yes
editor_options:
  markdown:
    wrap: 72
always_allow_html: yes
---

```{r setup, warning=FALSE, cache=FALSE, message=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(readxl)
library(MVN)
library(gridExtra)
library(lmtest)
library(car)
library(olsrr)
```

# 2.1. Modelo Aditivo 

## Ejercicio 2.1 Con el set de datos trees, disponible en la biblioteca dplyr de R, pretendemos ajustar un modelo que estimo el volumen (en pies cúbicos) de los árboles de cerezo en función de la longitud de su circunferencia (en pulgadas) y de su altura (en pies).

```{r}
library(dplyr)
```


### a) Visualizarla asociación entre las variables de a pares.




```{r}
pairs(trees, panel = panel.smooth, main = "trees data")
```
Sin embargo si hacemos el test de binormalidad vemos que no todas las variables son binormales. Por lo cual no sirve hacer correlación de perason para ambas

```{r}
rbind(mvn(data = trees[c(1,2)], mvnTest = "hz")$multivariateNormality,
      mvn(data = trees[c(1,3)], mvnTest = "hz")$multivariateNormality,
      mvn(data = trees[c(2,3)], mvnTest = "hz")$multivariateNormality
)

```


Entonces cambiamos de método:


```{r}
library(ggplot2)
library(GGally)
ggpairs(trees,    upper = list(continuous = wrap("cor",method="spearman")),
    lower =list(continuous = wrap("cor",method="pearson")))
```

Para girth y height hay que mirar la posicion 2,1. Para girth y volume 1,3 y para height volume 2,3


### b) Ajuste un modelo lineal simple para cada una de las dos predictoras disponibles.

**Volume ~ Girth

```{r}

model21_vg <- lm(Volume ~ Girth, data = trees)
promedios21 <- colMeans(trees)
ggplot(trees, aes(Volume, Girth)) + 
  geom_point() +
  geom_vline(xintercept=promedios21[3],linetype="dotted") + 
  geom_hline(yintercept=promedios21[1],linetype="dotted") +
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()

```
**Volume ~ Height**
**Volume ~ Girth**

```{r}
model21_vh <- lm(Volume ~ Height, data = trees)
promedios21 <- colMeans(trees)
ggplot(trees, aes(Volume, Height)) + 
  geom_point() +
  geom_vline(xintercept=promedios21[3],linetype="dotted") + 
  geom_hline(yintercept=promedios21[2],linetype="dotted") +
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```
### c) Realice un análisis diagnóstico en cada caso y señale en caso de haber los puntos influyentes y outliers.

#### Volume ~ Girth**

**Modelo lineal**
```{r}
summary(model21_vg)
```
Explica el 93% de los datos y los coeficientes tinene p-valores del test de wald por debajo de 0.05

**Normalidad**
```{r}
shapiro.test(model21_vg$residuals)
```
No rechaza normalidad

**Independencia**

```{r}
dwtest(model21_vg,alternative ="two.sided",iterations=1000)
```

La hipótesis nula es que NO hay autocorrelación, en este caso no rechaza pero por muy poco.....

**Homocedasticidad**

```{r}
bptest(model21_vg)
```
Los residuos son heterocedasticos porque se rechaza la hipotesis nula de homocedasticidad. Es decir que la varianza NO es constante para los diversos valores estimados.


**Resumen:**

 * Normalidad: Sí
 * Independencia: Sí 
 * Homcedasticidad: NO
 
 No se cumplen los supuestos entonce primero aplico una transformación de Box y Cox para ver si se resuelve el problema
 
```{r}
library(MASS)
box_cox_result <-boxcox(Volume ~ Girth, data = trees)
best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]
model21_vg_bc <- lm((Volume)^(best_box_cox) ~ Girth, data = trees)
```
 
```{r}
summary(model21_vg_bc)
```
Nuevamente los coeficientes tienen p-valores bajos para los test de wald de cada coeficiente dan ok y ahora explica el 95% de los datos.


**Normalidad**
```{r}
shapiro.test(model21_vg_bc$residuals)
```
No rechaza normalidad

**Independencia**

```{r}
dwtest(model21_vg_bc,alternative ="two.sided",iterations=1000)
```

La hipótesis nula es que NO hay autocorrelación, no la rechaza y por un valor más lejano

**Homocedasticidad**

```{r}
bptest(model21_vg_bc)
```
No se rechaza la homocedasticidad


**Resumen:**

 * Normalidad: Sí
 * Independencia: Sí 
 * Homcedasticidad: Sí


**Outliers** 

En relación a los outliers, no parece ser el caso de que haya outliers de influencia (si outliers que no son puntos de influencia). Hacemos el análisis

```{r}
par(mfrow=c(2,2))
plot(model21_vg)
par(mfrow=c(1,1))
```

```{r}
summary(influence.measures(model = model21_vg))
```
```{r}
influenceIndexPlot(model21_vg, vars='Bonf', las=1,col='green')
```

```{r}
outlierTest(model21_vg)
```

El punto 31 es un outlier, pero como box y cox resolvieron bastante bien no vale la pena hacer otro ajuste. Si aplicamos el test de puntos de influencia al modelo ajustado también obtenemos puntos, incluso algunos mas.

```{r}
summary(influence.measures(model = model21_vg_bc))
```

 
#### Volume ~ Height


**Modelo lineal**
```{r}
summary(model21_vh)
```
Explica el 33% de los datos y los coeficientes tienen p-valores del test de wald por debajo de 0.05

**Normalidad**
```{r}
shapiro.test(model21_vh$residuals)
```
No rechaza normalidad

**Independencia**

```{r}
dwtest(model21_vh,alternative ="two.sided",iterations=1000)
```

La hipótesis nula es que NO hay autocorrelación, en este caso si rechaza independecia o más bien NO autocorrelación de los residuos

**Homocedasticidad**

```{r}
bptest(model21_vh)
```
Los residuos son heterocedasticos porque se rechaza la hipotesis nula de homocedasticidad. Es decir que la varianza NO es constante para los diversos valores estimados.


**Resumen:**

 * Normalidad: Sí
 * Independencia: NO 
 * Homcedasticidad: NO
 
 No se cumplen los supuestos entonces primero aplico una transformación de Box y Cox para ver si se resuelve el problema
 
```{r}
library(MASS)
box_cox_result <-boxcox(Volume ~ Height, data = trees)
best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]
model21_vh_bc <- lm((Volume)^(best_box_cox) ~ Height, data = trees)
```
 
```{r}
summary(model21_vh_bc)
```
Nuevamente los coeficientes tienen p-valores bajos para los test de wald de cada coeficiente dan ok y ahora explica el 95% de los datos.


**Normalidad**
```{r}
shapiro.test(model21_vh_bc$residuals)
```
No rechaza normalidad

**Independencia**

```{r}
dwtest(model21_vh_bc,alternative ="two.sided",iterations=1000)
```

La hipótesis nula es que NO hay autocorrelación, la rechaza, por lo que hay autocorrelación

**Homocedasticidad**

```{r}
bptest(model21_vh_bc)
```
No se rechaza la homocedasticidad


**Resumen:**

 * Normalidad: NO
 * Independencia: NO 
 * Homcedasticidad: Sí
 
 Tampoco sirve.
 
 
**Outliers** 

Del análisis gráfico se ven varios puntos que pod´rian ser outliers y puntos de indluencia.

```{r}
par(mfrow=c(2,2))
plot(model21_vh)
par(mfrow=c(1,1))
```
 
```{r}
outlierTest(model21_vh)
```
Nuevamente el punto 31 se presenta como un outlier


```{r}
summary(influence.measures(model = model21_vh))
```
En este test aparecen tambien outliers, pero de los 4, el único que es outliers por los criterios considerados es el 31 (dffit)


Probemos aplicando un modelo robusto

```{r, echo=TRUE}
ww<-1 / lm(abs(model21_vh$residuals) ~ model21_vh$fitted.values)$fitted.values^2

plot(trees$Height,trees$Volume,xlab="Height",ylab="Volume",
     main="Horas vs Puntaje")

abline(model21_vh,col="darkviolet",lwd=2)

model21_vh_ww <- lm(Volume ~ Height, data = trees,weights =ww)
abline(model21_vh_ww,col="hotpink",lwd=2)
```
```{r}
summary(model21_vh_ww)
```
Vemos que en este caso mejora el R y el R ajustado del modelo por lo que es un mejor fit


**Normalidad**
```{r}
shapiro.test(model21_vh_ww$residuals)
```
No rechaza normalidad. pero por poco....

**Independencia**

NO SE PUEDE USAR DURBIN_WATSON

La hipótesis nula es que NO hay autocorrelación, la rechaza, por lo que hay autocorrelación

**Homocedasticidad**

```{r}
bptest(model21_vh_ww)
```
No rechaza homocedasticidad


**Resumen:**

 * Normalidad: Sí
 * Independencia: NO SE COMO TESTEARLO
 * Homcedasticidad: Sí




### d) Estime un intervalo de confianza para los coeficientes del modelo lineal estimado en cada caso

**Volumen ~ Girth**

```{r,echo=TRUE}
confint(model21_vg_bc)#por default el nivel es 0.95
```

```{r,echo=TRUE}
confint(model21_vh)#por default el nivel es 0.95
```



### e) Ajuste un nuevo modelo sin la/s observaciones influyentes

Vamos de nuevo sin la observación 31

```{r}
trees_adj <- trees[-c(31), ] 
```

```{r}
model21_vg_adj <- lm(Volume ~ Girth, data = trees_adj)
promedios21 <- colMeans(trees_adj)
ggplot(trees_adj, aes(Volume, Girth)) + 
  geom_point() +
  geom_vline(xintercept=promedios21[3],linetype="dotted") + 
  geom_hline(yintercept=promedios21[1],linetype="dotted") +
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```
```{r}
summary(model21_vg_adj)
```
Explica sólo el 93% de los datos

```{r}
model21_vh_adj <- lm(Volume ~ Height, data = trees_adj)
promedios21 <- colMeans(trees_adj)
ggplot(trees_adj, aes(Volume, Height)) + 
  geom_point() +
  geom_vline(xintercept=promedios21[3],linetype="dotted") + 
  geom_hline(yintercept=promedios21[2],linetype="dotted") +
   geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```
```{r}
summary(model21_vh_adj)
```
Explica sólo el 25% de los datos.


### f) Construya el intervalo de confianza y el de predicción del 95% par aun árbol cuyo diámetro es 16.1 pulgadas

Usamos el modelo de Volume ~ Girth ajustado por Box y Cox

```{r}
new_data <- data.frame(Girth = c(16.1))
# Predict the response variable using the model
predict(model21_vg_bc, newdata = new_data)

# Calculate the confidence interval
predict(model21_vg_bc, newdata = new_data, interval = "confidence")

# Calculate the prediction interval
predict(model21_vg_bc, newdata = new_data, interval = "prediction")
```

### g)Ajuste un modelo utilizando conjuntamente las dos variables predictoras y compare este ajuste con el mejor de los modelos anteriores mediante un test de modelos anidados. Concluya.

```{r}

model21_multi <- lm(Volume ~ Height + Girth, data = trees)
summary(model21_multi)
```
El R ajustado da que explica 94.5% de los datos. El estadístico F y los test de wald de los coeficientes dan por debajo de 0.05.

Veamos con un test de modelos anidados si realmente el modelo con mas variables mejora respecto al de una sola.

```{r}
anova(model21_multi,model21_vg)
```
El modelo de ambas variables es mejor que usando Girth sólo con este test. El tema es que no me queda claro como compararlo con el que se hizo con Box y Cox


# 2.2. Modelo con Interacción
## Ejercicio2.2. 
El departamento de ventas de una empresa quiere estudiar la influencia que tienen los distintos canales de publicidad sobre las ventas de un producto recién lanzado al mercado. Se dispone de un conjunto de datos que contiene los ingresos (en millones) conseguido por ventas en 200 regiones,así como la cantidad de presupuesto, también en millones, destinado a anuncios por radio,TV y periódicos en cada una de ellas. Los datos están disponibles en la base publicidad.xlsx

```{r warning=FALSE, cache=FALSE, message=FALSE}
pub22 <- read_excel('publicidad.xlsx')
```

### a) Ajustar un modelo de regresión lineal simple para cada una de las variables predictoras por separado. Realizar a continuación el análisis diagnóstico de los modelos.

```{r}
model22_tv <- lm(ventas ~ tv, data = pub22)
model22_ra <- lm(ventas ~ radio, data = pub22)
model22_pe <- lm(ventas ~ periodico, data = pub22)
summary(model22_tv)
summary(model22_ra)
summary(model22_pe)
```

Todos los coeficientes calculados son significativos

**Normalidad**
```{r}
shapiro.test(model22_tv$residuals)
shapiro.test(model22_ra$residuals)
shapiro.test(model22_pe$residuals)
```
Resultados: Sí,No,No

**Independencia**

```{r}
dwtest(model22_tv,alternative ="two.sided",iterations=1000)
dwtest(model22_ra,alternative ="two.sided",iterations=1000)
dwtest(model22_pe,alternative ="two.sided",iterations=1000)
```
Resultado: Sí,Sí,Sí

**Homocedasticidad**

```{r}
bptest(model22_tv)
bptest(model22_ra)
bptest(model22_pe)
```
Resultado: Sí,No,Sí

**Outliers**

```{r}
outlierTest(model22_tv)
```

```{r}
outlierTest(model22_ra)
```

```{r}
outlierTest(model22_pe)
```

Solo Radio parece tener outlier que es aquella que tenía problemas de heterocedasticidad y normalidad.

### b) Ajustar un modelo aditivo con las tres variables y decidir si alguna de ellas no es significativa (test de Wald).
```{r}
model22_multi <- lm(ventas ~ tv + radio + periodico, data = pub22)
summary(model22_multi)
```

Periódico falla el test de Wald, no es una variable significativa


### c) Ajustar los modelos de a pares y quedarse con el que mejor explique la variable respuesta utilizando elcriterio de AIC, R2 y Cp_Mallows.

```{r}
lm.fit1 <- lm(ventas ~ . , data = pub22[,-1])
k <- ols_step_all_possible(lm.fit1)
data.frame(k$predictors,k$adjr,k$cp,k$aic)
plot(k)
```

Otra forma con leaps:

```{r}
library(leaps)
regfit.todos <- regsubsets(ventas ~ . , data = pub22[,-1],nvmax=3)
summary.fit <- summary(regfit.todos)
summary.fit$outmat
which.max(summary.fit$adjr2)
which.min(summary.fit$cp)
which.min(summary.fit$bic)
coef(regfit.todos,2)
```

### d) Grafique para el modelo seleccionado el plano de ajuste y evalue si le parece adecuado.


### e) Considere el mejor modelo pero ahora con interacción. Compare los modelos con y sin interacción.



